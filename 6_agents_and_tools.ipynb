{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agents\n",
    "- What is it?\n",
    "    - LangChain Agents are like smart assistants for language models. They figure out what you want, use the right tools to get the information or complete a task, and then tell you the results.\n",
    "    - LangChain agents are like intelligent decision-makers that leverage language models (LLMs) to understand your requests and determine the best course of action. Unlike LLMs alone, which primarily generate text, agents can interact with external resources like APIs, databases, or even the command line through the use of specialized tools.\n",
    "- Why is it important?\n",
    "    - They're important because language models can't do everything on their own. Agents help them access information, perform actions, and solve complex problems they couldn't handle alone.\n",
    "## Types of Agents\n",
    "- Zero-shot-React-Description (Used in the Example):\n",
    "    - How it Works: The agent receives a description of the available tools and the user's request. It then decides which tool to use and how to format the input for the tool in a single step (zero-shot).\n",
    "    - When to Use: Great for simple tasks where the agent can make decisions quickly without needing to interact with the tools multiple times.\n",
    "- ReAct:\n",
    "    - How it Works: The agent iteratively interacts with the tools, thinking about the user's request and the results of each tool call to decide its next action.\n",
    "    - When to Use: Suitable for more complex tasks that require multiple steps or where the optimal tool might not be immediately clear.\n",
    "- Conversational ReAct:\n",
    "    - How it Works: Similar to ReAct, but specifically designed for conversational settings. It can handle multi-turn conversations and maintain context.\n",
    "    - When to Use: Ideal for building chatbots or virtual assistants where maintaining the conversation's flow is crucial.\n",
    "\n",
    "\n",
    "- Additional information about ReAct:\n",
    "    - ReAct stands for Reasoning and Acting. It is a prompting technique designed to enhance the reasoning capabilities of large language models (LLMs). The ReAct approach involves breaking down a complex task into smaller steps, where the LLM reasons about the current state, selects an action to take, observes the outcome of that action, and then repeats the process until the task is completed.\n",
    "\n",
    "\n",
    "\n",
    "- Rule of thumb to figure out which agent to use:\n",
    "    - If the task is simple and can be done in one step, use Zero-shot-React-Description.\n",
    "    - If the task is more complex and requires multiple steps or decisions, use ReAct.\n",
    "    - If the task involves a conversation or multiple interactions with the user, use Conversational ReAct.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Example\n",
    "from langchain.agents import Tool\n",
    "from langchain.agents import AgentType\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.agents import initialize_agent\n",
    "\n",
    "# Define your OpenAI API key\n",
    "OPENAI_API_KEY = 'YOUR_OPENAI_API_KEY'\n",
    "\n",
    "# Create a very simple tool\n",
    "def get_current_time():\n",
    "    \"\"\"Returns the current time in H:MM AM/PM format.\"\"\"\n",
    "    import datetime\n",
    "    now = datetime.datetime.now()\n",
    "    return now.strftime(\"%I:%M %p\")\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name = \"Time\",\n",
    "        func=get_current_time,\n",
    "        description=\"useful for when you need to know the current time\"\n",
    "    ),\n",
    "]\n",
    "llm = ChatOpenAI(openai_api_key=OPENAI_API_KEY, temperature=0)\n",
    "\n",
    "# Initialize an agent\n",
    "agent = initialize_agent(\n",
    "    tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True\n",
    ")\n",
    "\n",
    "# Test the agent\n",
    "response = agent.run(\"What time is it?\")\n",
    "print(response) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison Example   \n",
    "from langchain.agents import Tool\n",
    "from langchain.agents import AgentType\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents import ConversationalChatAgent, AgentExecutor\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.utilities import SerpAPIWrapper\n",
    "\n",
    "# 1. Define Tools\n",
    "# Define your OpenAI API key\n",
    "OPENAI_API_KEY = 'YOUR_OPENAI_API_KEY'\n",
    "llm = OpenAI(openai_api_key=OPENAI_API_KEY)\n",
    "\n",
    "def get_weather(location: str) -> str:\n",
    "    \"\"\"Gets the current weather in a given location.\"\"\"\n",
    "    from langchain.utilities import OpenWeatherMapAPIWrapper\n",
    "\n",
    "    weather_api = OpenWeatherMapAPIWrapper()\n",
    "    weather = weather_api.run(location)\n",
    "    return weather\n",
    "\n",
    "def get_fun_fact(subject: str) -> str:\n",
    "    \"\"\"Gets a fun fact about a given subject using SerpAPI.\"\"\"\n",
    "    search = SerpAPIWrapper()\n",
    "    params = {\n",
    "        \"engine\": \"google\",\n",
    "        \"q\": f\"fun fact about {subject}\",\n",
    "    }\n",
    "    return search.run(params)\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"GetWeather\",\n",
    "        func=get_weather,\n",
    "        description=\"useful for when you need to know the weather in a given location\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"GetFunFact\",\n",
    "        func=get_fun_fact,\n",
    "        description=\"useful for when you want to find a fun fact about a given subject\"\n",
    "    )\n",
    "]\n",
    "\n",
    "# 2. Initialize Zero-Shot and ReAct Agents\n",
    "query = \"What's the weather in London, and tell me a fun fact about the city?\"\n",
    "print(\"Zero-Shot Agent:\")\n",
    "agent_zero = initialize_agent(\n",
    "    tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True\n",
    ")\n",
    "agent_zero.run(query)\n",
    "\n",
    "print(\"\\nReAct Agent:\")\n",
    "agent_react = initialize_agent(\n",
    "    tools, llm, agent=AgentType.REACT_DOCSTORE, verbose=True\n",
    ")\n",
    "agent_react.run(query)\n",
    "\n",
    "# 3. Initialize Conversational Agent\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
    "agent_conversational = ConversationalChatAgent.from_llm_and_tools(llm, tools, memory=memory)\n",
    "\n",
    "# 4. Run the Conversational Agent\n",
    "agent_executor = AgentExecutor.from_agent_and_tools(agent=agent_conversational, tools=tools, verbose=True)\n",
    "print(\"\\nConversational ReAct Agent:\")\n",
    "agent_executor.run(\"What's the weather like in London today?\")  \n",
    "agent_executor.run(\"That's interesting. Now, can you tell me a fun fact about London?\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zero-Shot Agent's Thoughts:\n",
    "\n",
    "Prompt: \"What's the weather in London, and tell me a fun fact about the city?\"\n",
    "\n",
    "Reasoning:\n",
    "\n",
    "Analyze the query: The query has two parts: one about weather and one about a fun fact.\n",
    "Tool Selection: I can use both the GetWeather tool for the weather information and the GetFunFact tool for the fun fact.\n",
    "Execute Tools: I'll run both tools simultaneously, one to fetch the weather in London and the other to search for a fun fact about London.\n",
    "Combine Results: Once I have the results from both tools, I'll combine them into a single response.\n",
    "ReAct Agent's Thoughts:\n",
    "\n",
    "Prompt: \"What's the weather in London, and tell me a fun fact about the city?\"\n",
    "\n",
    "Reasoning:\n",
    "\n",
    "Analyze the query: The query has two parts, but I'll tackle them one by one.\n",
    "First Task: I need to find the weather in London, so I'll use the GetWeather tool.\n",
    "Execute GetWeather: [Calls the tool and receives the weather information]\n",
    "Second Task: Now I need to find a fun fact about London. I'll use the GetFunFact tool.\n",
    "Execute GetFunFact: [Calls the tool and receives a fun fact]\n",
    "Combine Results: I'll combine the weather information and the fun fact into a single response.\n",
    "Conversational ReAct Agent's Thoughts:\n",
    "\n",
    "Prompt 1: \"What's the weather like in London today?\"\n",
    "\n",
    "Reasoning:\n",
    "\n",
    "Analyze the query: The user wants to know about the weather in London.\n",
    "Tool Selection: I'll use the GetWeather tool.\n",
    "Execute GetWeather: [Calls the tool and receives the weather information]\n",
    "Formulate Response: I'll tell the user the current weather in London.\n",
    "Store Information: I'll remember that we were talking about London for the next turn.\n",
    "Prompt 2: \"That's interesting. Now, can you tell me a fun fact about London?\"\n",
    "\n",
    "Reasoning:\n",
    "\n",
    "Analyze the query: The user wants to know a fun fact about London.\n",
    "Recall Context: I remember from the previous turn that we were talking about London.\n",
    "Tool Selection: I'll use the GetFunFact tool, since I already know the location.\n",
    "Execute GetFunFact: [Calls the tool and receives a fun fact about London]\n",
    "Formulate Response: I'll tell the user the fun fact I found."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tools\n",
    "- What is it?\n",
    "    - Think of tools as specialized actions your language model can take to interact with the world beyond just text.  They are like different skills or abilities you can give your LLM to make it more useful and versatile.\n",
    "- Examples of Tools:\n",
    "    - Search Tool: Looks up information on the internet (like Google Search).\n",
    "    - Calculator: Performs mathematical calculations.\n",
    "    - Database Lookup: Queries a database to retrieve specific information.\n",
    "    - Code Execution: Runs code snippets and returns the results.\n",
    "    - Image Generation: Creates images based on text descriptions.\n",
    "- Why use tools:\n",
    "    - Access to Real-World Information: LLMs are trained on static data, but tools can get them up-to-date info from the web or other sources.\n",
    "    - Perform Actions: Tools let LLMs do things besides just generate text, making them more interactive and helpful.\n",
    "    - Solve Complex Problems: Many problems require multiple steps, like looking up info, doing calculations, and then summarizing the results. Tools help break these down.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import BaseTool\n",
    "\n",
    "class MyCalculatorTool(BaseTool):\n",
    "    name = \"Calculator\"\n",
    "    description = \"Useful for when you need to perform mathematical calculations.\"\n",
    "\n",
    "    def _run(self, query: str) -> str:\n",
    "        \"\"\"Use the calculator.\"\"\"\n",
    "        try:\n",
    "            result = eval(query)  # Be careful with `eval` in production!\n",
    "            return str(result)\n",
    "        except Exception as e:\n",
    "            return f\"Error: {e}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's happening under the hood with this example when working with agents:\n",
    "\n",
    "This is where agents come in. The agent acts as the \"brain\" that decides which tool to use based on your input. Here's how they work together:\n",
    "\n",
    "You: \"What's 25 times 12?\"\n",
    "Agent: (Thinks) \"This sounds like a math problem. I'll use the Calculator tool.\"\n",
    "Agent (to Calculator): \"25 * 12\"\n",
    "Calculator: \"300\"\n",
    "Agent (to You): \"The answer is 300.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- LangChain Tools: https://python.langchain.com/v0.1/docs/integrations/tools/\n",
    "\n",
    "    - Search Engines:\n",
    "        - SerpAPIWrapper (requires API key)\n",
    "        - TavilySearchResults (requires API key)\n",
    "        - DuckDuckGoSearchRun\n",
    "        - FireCrawl\n",
    "        - TODO: Show output for each tool in the list for same website.\n",
    "    - Wikipedia:\n",
    "\n",
    "        - WikipediaQueryRun\n",
    "    - Code Execution:\n",
    "\n",
    "        - PythonREPLTool\n",
    "    - Other:\n",
    "\n",
    "        - WolframAlphaAPIWrapper (requires API key)\n",
    "        - RequestsGetTool (for making HTTP GET requests)\n",
    "        - Many more in langchain_community.tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple tool constructor\n",
    "\n",
    "from langchain.tools import Tool\n",
    "from langchain.utilities import SerpAPIWrapper\n",
    "import random\n",
    "\n",
    "def recommend_movie(genre: str) -> str:\n",
    "    \"\"\"Recommends a movie based on genre using SerpAPI.\"\"\"\n",
    "    search = SerpAPIWrapper()\n",
    "    params = {\n",
    "        \"engine\": \"google\",\n",
    "        \"q\": f\"best {genre} movies\"\n",
    "    }\n",
    "    results = search.run(params)  \n",
    "    # Extract movie titles from the search results (this is simplified for the demo)\n",
    "    movies = [title for title in results.split(\"\\n\") if title]  \n",
    "    return random.choice(movies) if movies else \"No movies found for that genre.\"\n",
    "\n",
    "movie_recommender_tool = Tool(\n",
    "    name=\"MovieRecommender\",\n",
    "    func=recommend_movie,\n",
    "    description=\"Useful for when you want to get a movie recommendation for a specific genre.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain.tools import tool\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "# Define your OpenAI API key\n",
    "OPENAI_API_KEY = 'YOUR_OPENAI_API_KEY'\n",
    "llm = OpenAI(openai_api_key=OPENAI_API_KEY)\n",
    "\n",
    "@tool(\"Current Time\", \"Get the current time in your location.\")\n",
    "def get_current_time() -> str:\n",
    "    \"\"\"\n",
    "    This tool returns the current time in your location.\n",
    "    \"\"\"\n",
    "    from datetime import datetime\n",
    "\n",
    "    now = datetime.now()\n",
    "    return f\"Current time is {now.strftime('%Y-%m-%d %H:%M:%S')}\"\n",
    "\n",
    "tools = [get_current_time]  # The decorator automatically creates the Tool object\n",
    "agent = initialize_agent(tools, llm, agent=\"zero-shot-react-description\", verbose=True)\n",
    "\n",
    "response = agent.run(\"What time is it?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Tool Constructor Approach:\n",
    "\n",
    "    - When you need fine-grained control over input validation.\n",
    "    - When you want to pass multiple arguments of different types to the tool.\n",
    "    - When your tool's logic is more complex and might benefit from a separate function definition.\n",
    "\n",
    "- @tool Decorator Approach:\n",
    "\n",
    "    - When you want to quickly create a simple tool with a single string input and string/dictionary output.\n",
    "    - When you plan to share your tool on LangChainHub.\n",
    "    - When you prefer concise and self-documenting code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import BaseTool\n",
    "import random\n",
    "\n",
    "class MovieRecommenderTool(BaseTool):\n",
    "    name = \"MovieRecommender\"\n",
    "    description = \"Useful for recommending movies based on a genre. Input should be the genre you are interested in.\"\n",
    "\n",
    "    def _run(self, genre: str) -> str:\n",
    "        \"\"\"Run the movie recommender.\"\"\"\n",
    "        movies = {\n",
    "            \"Action\": [\"Die Hard\", \"Mad Max: Fury Road\"],\n",
    "            \"Comedy\": [\"21 Jump Street\", \"The Hangover\"],\n",
    "            \"Sci-Fi\": [\"Blade Runner\", \"Interstellar\"],\n",
    "            # ... (Add more genres and movies here)\n",
    "        }\n",
    "        if genre in movies:\n",
    "            return random.choice(movies[genre])\n",
    "        else:\n",
    "            return \"I'm not familiar with that genre yet.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import BaseTool\n",
    "from pydantic import Field, BaseModel\n",
    "import random\n",
    "\n",
    "# Define the Pydantic model for input validation\n",
    "# Helps agent to determine parameters, types, and any validation rules\n",
    "class MovieRecommenderInput(BaseModel):\n",
    "    genre: str = Field(description=\"The genre of movie you're interested in.\")\n",
    "\n",
    "# Define the MovieRecommender tool\n",
    "class MovieRecommenderTool(BaseTool):\n",
    "    name = \"MovieRecommender\"\n",
    "    description = \"Useful for recommending movies based on a genre.\"\n",
    "    args_schema: MovieRecommenderInput  # Use the Pydantic model for input validation\n",
    "\n",
    "    def _run(self, genre: str) -> str:\n",
    "        \"\"\"Run the movie recommender.\"\"\"\n",
    "        # A larger movie dataset for demonstration purposes (you could replace with API calls)\n",
    "        movies = {\n",
    "            \"Action\": [\"Die Hard\", \"Mad Max: Fury Road\", \"John Wick\", \"The Raid: Redemption\"],\n",
    "            \"Comedy\": [\"21 Jump Street\", \"The Hangover\", \"Booksmart\", \"Bridesmaids\"],\n",
    "            \"Sci-Fi\": [\"Blade Runner\", \"Interstellar\", \"Arrival\", \"Dune\"],\n",
    "            \"Drama\": [\"The Shawshank Redemption\", \"The Godfather\", \"Parasite\", \"12 Angry Men\"],\n",
    "            \"Horror\": [\"The Shining\", \"Get Out\", \"Hereditary\", \"A Quiet Place\"],\n",
    "        }\n",
    "\n",
    "        if genre.lower() in movies:  # Case-insensitive genre matching\n",
    "            return random.choice(movies[genre.lower()])\n",
    "        else:\n",
    "            return \"I'm not familiar with that genre yet. Try a different one!\"\n",
    "\n",
    "# Example usage with an agent (not necessary for the tool itself)\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# Define your OpenAI API key\n",
    "OPENAI_API_KEY = 'YOUR_OPENAI_API_KEY'\n",
    "llm = ChatOpenAI(openai_api_key=OPENAI_API_KEY)\n",
    "\n",
    "tools = [MovieRecommenderTool()]\n",
    "agent = initialize_agent(tools, llm, agent=\"zero-shot-react-description\", verbose=True)\n",
    "\n",
    "agent.run(\"Recommend a good sci-fi movie.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import BaseTool\n",
    "from pydantic import Field, BaseModel\n",
    "import random\n",
    "\n",
    "# Define the Pydantic model for input validation\n",
    "class MovieRecommenderInput(BaseModel):\n",
    "    genre: str = Field(description=\"The genre of movie you're interested in.\")\n",
    "\n",
    "# Define the Pydantic model for output (two movie recommendations)\n",
    "class MovieRecommenderOutput(BaseModel):\n",
    "    primary_recommendation: str = Field(description=\"The primary movie recommendation.\")\n",
    "    backup_recommendation: str = Field(description=\"An alternative movie recommendation.\")\n",
    "\n",
    "# Define the MovieRecommender tool\n",
    "class MovieRecommenderTool(BaseTool):\n",
    "    name = \"MovieRecommender\"\n",
    "    description = \"\"\"\n",
    "    Useful for recommending movies based on a genre. \n",
    "    Input should be a single word representing the genre (e.g., \"action\", \"comedy\", \"sci-fi\").\n",
    "    \"\"\"\n",
    "    args_schema: MovieRecommenderInput    # Input validation\n",
    "    return_direct: bool = True            # Return as dictionary \n",
    "\n",
    "    def _run(self, genre: str) -> MovieRecommenderOutput:\n",
    "        \"\"\"Run the movie recommender.\"\"\"\n",
    "        movies = {\n",
    "            \"Action\": [\"Die Hard\", \"Mad Max: Fury Road\", \"John Wick\", \"The Raid: Redemption\"],\n",
    "            \"Comedy\": [\"21 Jump Street\", \"The Hangover\", \"Booksmart\", \"Bridesmaids\"],\n",
    "            \"Sci-Fi\": [\"Blade Runner\", \"Interstellar\", \"Arrival\", \"Dune\"],\n",
    "            \"Drama\": [\"The Shawshank Redemption\", \"The Godfather\", \"Parasite\", \"12 Angry Men\"],\n",
    "            \"Horror\": [\"The Shining\", \"Get Out\", \"Hereditary\", \"A Quiet Place\"],\n",
    "        }\n",
    "\n",
    "        genre = genre.lower()  # Case-insensitive genre matching\n",
    "        if genre in movies and len(movies[genre]) >= 2:\n",
    "            # Sample two movies randomly, ensuring they are different\n",
    "            primary, backup = random.sample(movies[genre], 2)\n",
    "        elif genre in movies:\n",
    "            primary = random.choice(movies[genre])\n",
    "            backup = \"I couldn't find another movie in that genre, sorry!\"\n",
    "        else:\n",
    "            primary = backup = \"I'm not familiar with that genre yet. Try a different one!\"\n",
    "\n",
    "        # Return the recommendations as a MovieRecommenderOutput object (which will be converted to a dict)\n",
    "        return MovieRecommenderOutput(primary_recommendation=primary, backup_recommendation=backup)\n",
    "\n",
    "# Example usage\n",
    "tool = MovieRecommenderTool()\n",
    "result = tool.run(\"sci-fi\")\n",
    "print(result) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LangChain Tools Cheat Sheet\n",
    "What are Tools?\n",
    "Think of tools as superpowers for your language models (LLMs). Tools let your LLM interact with the world beyond just text. They can search the web, perform calculations, access databases, run code, and much more.\n",
    "\n",
    "Why Use Tools?\n",
    "Give your LLM access to up-to-date information (it only knows what it was trained on).\n",
    "Enable your LLM to take actions (not just generate text).\n",
    "Solve complex tasks that require multiple steps.\n",
    "\n",
    "3 ways to create tools:\n",
    "- Tool Constructor Approach: For fine-grained control and complex logic.\n",
    "- @tool Decorator Approach: For quick and simple tools.\n",
    "- Pydantic Validation: For input validation and type checking.\n",
    "\n",
    "Using tools with agents:\n",
    "\n",
    "`tools = [my_tool, another_tool, ...]`\n",
    "\n",
    "\n",
    "Initializing agents:\n",
    "```python\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True\n",
    ")\n",
    "```\n",
    "\n",
    "Run it:\n",
    "`agent.run(\"Your query here\")`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
