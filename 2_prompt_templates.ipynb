{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Templates\n",
    "- What is it?\n",
    "    - Prompt templates allow us to create a template for a prompt that includes variables that can be replaced with values.\n",
    "- Why is it important?\n",
    "    - They make it super easy for us to take in raw input from our users and construct a prompt that's ready to pass to a language model.\n",
    "- What problem does it solve for us?\n",
    "    - It is super common for us to want to ask the same question multiple times with slight variations. Prompt templates allow us to define a template for a prompt and then easily replace variables with values.\n",
    "    - Without prompt templates, we would have to manually construct the prompt each time we want to ask a question.\n",
    "- How do I use it? \n",
    "    - \n",
    "- Desired end goal.\n",
    "    - Prompts that we can pass to a language model that are ready to go.\n",
    "- Additional use cases with examples.\n",
    "    - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Make sure to show people the final state of a prompt templates then wakl them through the process of how to get there.\n",
    "- Also, walk them through the comparison of what it would look like without prompt templates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "load_dotenv() \n",
    "model = ChatOpenAI(model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without prompt templates\n",
    "# Wanted to create an AI tutor for students at different grade levels on different subjects\n",
    "\n",
    "from typing import List\n",
    "from langchain_core.messages import BaseMessage, SystemMessage, HumanMessage\n",
    "\n",
    "student_help_queue = [\n",
    "    {\n",
    "        \"subject\": \"Math\",\n",
    "        \"grade\": \"4th Grade\",\n",
    "        \"question\": \"Can you walk me through how to add fractions?\"\n",
    "    },\n",
    "    {\n",
    "        \"subject\": \"Science\",\n",
    "        \"grade\": \"7th Grade\",\n",
    "        \"question\": \"How do I calculate the density of an object?\"\n",
    "    }\n",
    "]\n",
    "\n",
    "messages: List[List[BaseMessage]] = []\n",
    "\n",
    "for student in student_help_queue:\n",
    "    system_message = SystemMessage(f\"Student needs help with {student['subject']} in {student['grade']} grade\")\n",
    "    human_message = HumanMessage(f\"Can you help me with {student['question']}\")\n",
    "    messages.append([system_message, human_message])\n",
    "\n",
    "for index, message in enumerate(messages):\n",
    "    response = model.invoke(message)\n",
    "    print(f\"Response {index}: \",response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[SystemMessage(content='You are a helpful AI bot that teaches {subject} to {grade} students.'), HumanMessage(content='{question}')]\n",
      "I see that your placeholders are empty. Could you please provide specific details about the subject, grade level, and the question you'd like to ask? This will help me give you the most accurate and helpful response.\n",
      "messages=[SystemMessage(content='You are a helpful AI bot that teaches {subject} to {grade} students.'), HumanMessage(content='{question}')]\n",
      "It looks like there are placeholders in your message. Could you please provide more specific details about the subject you want to discuss and the grade level of the students? That way, I can give you a more accurate and helpful response!\n"
     ]
    }
   ],
   "source": [
    "# With prompt templates\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "student_help_queue = [\n",
    "    {\n",
    "        \"subject\": \"Math\",\n",
    "        \"grade\": \"4th Grade\",\n",
    "        \"question\": \"Can you walk me through how to add fractions?\"\n",
    "    },\n",
    "    {\n",
    "        \"subject\": \"Science\",\n",
    "        \"grade\": \"7th Grade\",\n",
    "        \"question\": \"How do I calculate the density of an object?\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# TODO: Talk about how this new \"system\", \"human\", and \"ai\" tuple approach is different\n",
    "template = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"You are a helpful AI bot that teaches {subject} to {grade} students.\"),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ])\n",
    "\n",
    "for student in student_help_queue:\n",
    "    prompt = template.invoke(student)\n",
    "    print(prompt)\n",
    "    response = model.invoke(prompt)\n",
    "    print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Setup something like this but for my example to show users before we get started so they can see how we are generating prompts very cleanly.\n",
    "\n",
    "\n",
    "            from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "            template = ChatPromptTemplate.from_messages([\n",
    "                (\"system\", \"You are a helpful AI bot. Your name is {name}.\"),\n",
    "                (\"human\", \"Hello, how are you doing?\"),\n",
    "                (\"ai\", \"I'm doing well, thanks!\"),\n",
    "                (\"human\", \"{user_input}\"),\n",
    "            ])\n",
    "\n",
    "            prompt_value = template.invoke(\n",
    "                {\n",
    "                    \"name\": \"Bob\",\n",
    "                    \"user_input\": \"What is your name?\"\n",
    "                }\n",
    "            )\n",
    "            # Output:\n",
    "            # ChatPromptValue(\n",
    "            #    messages=[\n",
    "            #        SystemMessage(content='You are a helpful AI bot. Your name is Bob.'),\n",
    "            #        HumanMessage(content='Hello, how are you doing?'),\n",
    "            #        AIMessage(content=\"I'm doing well, thanks!\"),\n",
    "            #        HumanMessage(content='What is your name?')\n",
    "            #    ]\n",
    "            #)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple ChatPromptTemplate.from_template\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# Define your OpenAI API key\n",
    "OPENAI_API_KEY = 'YOUR_OPENAI_API_KEY'\n",
    "\n",
    "# Initialize ChatOpenAI model\n",
    "chat = ChatOpenAI(openai_api_key=OPENAI_API_KEY, temperature=0.7)\n",
    "\n",
    "# Create a simpler ChatPromptTemplate\n",
    "template = \"Tell me a joke about {topic}.\"  # No need for \"Human:\" or \"Assistant:\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# Format the prompt and get the response\n",
    "formatted_prompt = prompt.format_prompt(topic=\"dogs\")\n",
    "response = chat(formatted_prompt.to_messages())\n",
    "print(response.content) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- TODO:\n",
    "    - From template\n",
    "    - From messages\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchaincc311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
